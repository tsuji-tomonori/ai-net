---
title_en: "HiPhO: How Far Are (M)LLMs from Humans in the Latest High School Physics Olympiad Benchmark?"
title_ja: "HiPhO: 最新の高校物理オリンピック・ベンチマークで(M)LLMは人間からどれだけ離れているか"
aliases: ["HiPhO", "Physics Olympiad Benchmark", "(M)LLM Physics"]
tags: [paper, benchmark, MLLM, LLM, physics, multimodal, evaluation]
status: note
venue: arXiv
year: 2025
authors:
  - Fangchen Yu
  - Haiyuan Wan
  - Qianjia Cheng
  - Yuchen Zhang
  - Jiacheng Chen
  - Fujun Han
  - Yulun Wu
  - Junchi Yao
  - Ruilizhen Hu
  - Ning Ding
  - Yu Cheng
  - Tao Chen
  - Lei Bai
  - Dongzhan Zhou
  - Yun Luo
  - Ganqu Cui
  - Peng Ye
arxiv: "2509.07894"
version: "v2"
links:
  - abs: https://arxiv.org/abs/2509.07894
  - pdf: https://arxiv.org/pdf/2509.07894v2.pdf
created: 2025-09-14
---

# HiPhO: How Far Are (M)LLMs from Humans in the Latest High School Physics Olympiad Benchmark? / HiPhO: 最新の高校物理オリンピック・ベンチマークで(M)LLMは人間からどれだけ離れているか

## 概要（3行で）
- 目的: 高校物理オリンピックに整合した人間基準の評価で、(M)LLMの物理的推論・解答能力を最新の試験群で測る。
- アプローチ: 2024–2025年の計13試験を収集し、テキスト〜図表を含む混合モダリティ、公式採点基準に基づく解答/ステップ単位の細粒度採点、人間（メダル閾値）との直接比較を実現。
- 結果: 30モデルの大規模評価で、OSS MLLMは概ね銅相当以下、OSS LLMは一部金到達、クローズド推論MLLMは6–12個の金を獲得するが、満点とのギャップは大きい。

## 主な貢献
- 高校物理オリンピックに特化したベンチマークHiPhOの提示（13試験、2024–2025、混合モダリティ）。
- 公式の採点スキームに準拠した解答・ステップ単位の専門的評価で、人間採点者に整合。
- メダル閾値（金・銀・銅）に基づく人間レベル比較により、(M)LLMと受験生の直接比較を可能化。
- 30の最先端(M)LLM評価から、オープンとクローズド、LLMとMLLMの性能差と改善余地を総覧。

## 手法 / 設計
- 問題設定: 物理オリンピックの理論問題を対象に、テキストのみ/図表含みの混合モダリティを網羅。
- 評価設計: 公式採点基準に従い、最終解答だけでなく解法過程（ステップ）を細粒度採点し、部分点を反映。
- 人間比較: 各試験の公式メダルスコアライン（金/銀/銅）にマッピングしてモデルの相対位置を可視化。

## 実験・評価（要約）
- セットアップ: 2024–2025の13試験（国際＋地域）を統合。混合モダリティ課題を含む。
- 比較条件: オープン/クローズド、LLM/MLLM、推論特化型モデルなど30モデルを横断比較。
- 指標: 試験ごとの総合スコア、メダル到達数、設問タイプ別（テキスト/図表）の強弱、満点ギャップ。

## 主要結果
- OSS MLLMは多くが銅レベル相当以下に留まる。
- OSS LLMは一部試験で金メダル到達例がある。
- クローズドの推論MLLMは6–12個の金メダルに到達する強さを示す。
- 多くのモデルで依然として満点との顕著な差が残る。

## 考察・限界
- 位置づけ: 物理オリンピックという厳格なドメインで、人間採点に整合した混合モダリティ評価を提供。
- 限界: 問題や採点の詳細は競技特有で、一般的学術物理や実験系タスクへの外挿には注意が必要。
- 将来課題: 図表理解と多段推論の強化、解法ステップの一貫性・正当化、説明可能性の付与。

## 再現性メモ
- データ/環境: 2024–2025のオリンピック試験セット（テキスト＋図表）。
- 評価/採点: 公式マークスキーム準拠のステップ単位採点（人間基準に整合）。
- コード/公開: リポジトリ（論文より）: https://github.com/SciYu/HiPhO

## 応用・拡張アイデア
- 教育評価: 逐次解法の評価・フィードバックに基づく学習補助。
- モデル診断: ステップ単位の誤答分析で、計画・図表理解・計算の弱点を特定。
- マルチモーダル推論: 図表→テキストの表現変換や外部ツール併用での精度改善。

## キークォート
> "We present HiPhO, the first benchmark dedicated to high school physics Olympiads with human-aligned evaluation..."

> "Across 13 exams, open-source MLLMs mostly remain at or below the bronze level; ... closed-source reasoning MLLMs can achieve 6 to 12 gold medals; and most models still have a significant gap from full marks."

## 用語メモ（words/ を使う）
- [[words/long-horizon-execution]]: 長い解法過程の正確性という観点（関連）。
- [[words/sequential-test-time-compute]]: 推論特化型・逐次計算の強化が得点に与える影響（関連）。

## 関連研究
- 科学・数学オリンピック系ベンチマーク、図表理解を含むMLLM評価、ステップ採点に基づく連鎖推論評価。

## BibTeX
```bibtex
@misc{yu2025hipho,
  title         = {HiPhO: How Far Are (M)LLMs from Humans in the Latest High School Physics Olympiad Benchmark?},
  author        = {Fangchen Yu and Haiyuan Wan and Qianjia Cheng and Yuchen Zhang and Jiacheng Chen and Fujun Han and Yulun Wu and Junchi Yao and Ruilizhen Hu and Ning Ding and Yu Cheng and Tao Chen and Lei Bai and Dongzhan Zhou and Yun Luo and Ganqu Cui and Peng Ye},
  year          = {2025},
  eprint        = {2509.07894},
  archivePrefix = {ArXiv},
  primaryClass  = {cs.AI},
  url           = {https://arxiv.org/abs/2509.07894}
}
```

## リンク
- arXiv: https://arxiv.org/abs/2509.07894
- PDF: https://arxiv.org/pdf/2509.07894v2.pdf
