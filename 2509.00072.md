---
title_en: "Beyond Memorization: Reasoning-Driven Synthesis as a Mitigation Strategy Against Benchmark Contamination"
title_ja: "記憶依存を超えて: ベンチマーク汚染の緩和策としての推論駆動型シンセシス"
aliases: ["Reasoning-Driven Synthesis", "Benchmark Contamination Mitigation"]
tags: [paper, LLM, evaluation, contamination, reasoning]
status: note
venue: arXiv
year: 2025
authors:
  - Terry Jingchen Zhang
  - Gopal Dev
  - Ning Wang
  - Nicole Ni
  - Wenyuan Jiang
  - Yinya Huang
  - Bernhard Schölkopf
  - Mrinmaya Sachan
  - Zhijing Jin
arxiv: "2509.00072"
version: "v1"
links:
  - abs: https://arxiv.org/abs/2509.00072
  - pdf: https://arxiv.org/pdf/2509.00072v1.pdf
created: 2025-09-15
---

# Beyond Memorization: Reasoning-Driven Synthesis as a Mitigation Strategy Against Benchmark Contamination / 記憶依存を超えて: ベンチマーク汚染の緩和策としての推論駆動型シンセシス

## 概要（3行で）
- 目的: LLM評価におけるデータ汚染の影響を検証し、丸暗記ではなく推論能力を測るための研究レベルQAをarXiv論文から合成する枠組みを提示。
- アプローチ: 26カ月にわたる時間層別化で20,277本の論文から1,643問の多段推論QAを作成し、知識カットオフの異なるモデル群（主要開発元4社のフロンティア計8モデル）を比較。
- 結果: 知識カットオフ前後で有意な性能低下は観測されず。直接回収問題に依拠する先行縦断研究の「ポストカットオフ低下」と対照的に、推論駆動の合成が浅い記憶効果を抑え、汚染緩和に有効である可能性を示唆。

## 主な貢献
- 時系列に整合した研究レベルQA合成フレーム（無制限にスケール可能）を提案し、汚染検出に適した評価設計を提示。
- 26カ月・20,277本の論文から1,643問を作成し、月次粒度で評価できるデータセットを構築。
- 知識カットオフの異なる複数モデル（開発元横断）に対し、カットオフ近傍でも顕著な性能低下が見られないことを一貫して観測。
- 先行の「直接回収型」評価と比較し、多段推論要求が記憶依存を超える複雑性を与え、汚染リスクを下げうることを示唆。
- コードとデータセットを公開し、再現性と追試を促進。

## 手法 / 設計
- 問題設定: 静的ベンチマークが訓練データ汚染の影響で「推論」ではなく「記憶」を測ってしまう問題。
- 提案手法: arXiv論文から研究レベルの多段推論QAを自動合成し、知識カットオフ前後の月次ウィンドウで性能推移を解析。
- 実装要点: 月次の時間層別化、論文本文に基づくクエリ生成、複数モデル・複数カットオフの横断比較、長期（26カ月）カバレッジ。

## 実験・評価（要約）
- セットアップ: 数学・物理領域のarXiv論文20,277本から1,643問を生成し、26カ月の月次バケットに配置。
- 比較条件: 主要開発元4社のフロンティアモデル計8種（各ファミリで異なる知識カットオフ）を評価。
- 指標: 合成QAに対する回答正確度などの性能指標を月次で集計し、カットオフ近傍の変化を検定。

## 主要結果
- すべてのモデル群で、知識カットオフ近傍の顕著な性能低下は観測されず。
- 直接回収に依存した評価では報告される「ポストカットオフ低下」と異なる傾向。
- 推論駆動の合成QAは、浅い記憶効果によるスコアの水増しに頑健。

## 考察・限界
- 位置づけ: ベンチマーク汚染への緩和策として、推論要求の高い合成ベンチマークの有用性を裏付け。
- 限界: 合成プロセス由来のバイアス、領域（数物中心）のカバレッジ、評価指標の設計選好が残る可能性。
- 将来課題: 他領域・他形式（コード、マルチモーダル）への拡張、難易度較正、自動合成の品質評価の標準化。

## 再現性メモ
- コード/データ: 公開（論文付随リポジトリ）。時間層別化・QA生成のスクリプトで再現可能。
- データ/環境: arXiv本文由来のテキスト処理と月次バケット化。モデルは知識カットオフの異なる複数バージョンを使用。
- ログ/設定: 月次集計・カットオフ近傍比較の解析スクリプトを用意。

## 応用・拡張アイデア
- 学習時のデータ検疫評価: 事前学習/微調整データの汚染検出の補助指標として利用。
- ベンチマーク設計: 領域横断で推論要求の高い合成問題を標準化し、時系列で継続評価。

## キークォート
> "the multi-step reasoning required by our synthesis pipeline ... effectively serves a mitigation strategy against benchmark contamination."

## 用語メモ（words/ を使う）
- [[words/controllability]]: 評価設計における制御可能な難易度・時間層別化。
- [[words/explainability]]: 推論過程の妥当性検証と説明可能性の観点（参考）。
- [[words/long-horizon-execution]]: 長期にわたる評価設計とモニタリングの示唆。

## 関連研究
- データ汚染の縦断評価（直接回収型）との比較研究、および推論重視のベンチマーク設計に関する近年の議論。

## BibTeX
```bibtex
@misc{zhang2025beyond,
  title         = {Beyond Memorization: Reasoning-Driven Synthesis as a Mitigation Strategy Against Benchmark Contamination},
  author        = {Terry Jingchen Zhang and Gopal Dev and Ning Wang and Nicole Ni and Wenyuan Jiang and Yinya Huang and Bernhard Schölkopf and Mrinmaya Sachan and Zhijing Jin},
  year          = {2025},
  eprint        = {2509.00072},
  archivePrefix = {arXiv},
  primaryClass  = {cs.AI},
  url           = {https://arxiv.org/abs/2509.00072}
}
```

## リンク
- arXiv: https://arxiv.org/abs/2509.00072
- PDF: https://arxiv.org/pdf/2509.00072v1.pdf

