---
title_en: "YOLO-Stutter: End-to-end Region-Wise Speech Dysfluency Detection"
title_ja: "YOLO-Stutter: エンドツーエンドの領域別音声非流暢性検出"
aliases: ["YOLO-Stutter"]
tags: [paper, speech, dysfluency, detection]
status: note
venue: arXiv
year: 2024
authors:
  - Xuanru Zhou
  - Anshul Kashyap
  - Steve Li
  - Ayati Sharma
  - Brittany Morin
  - David Baquirin
  - Jet Vonk
  - Zoe Ezzes
  - Zachary Miller
  - Maria Luisa Gorno-Tempini
  - Jiachen Lian
  - Gopala Krishna Anumanchipalli
arxiv: "2408.15297"
version: "v3"
links:
  - abs: https://arxiv.org/abs/2408.15297
  - pdf: https://arxiv.org/pdf/2408.15297v3.pdf
created: 2025-09-15
---

# YOLO-Stutter: End-to-end Region-Wise Speech Dysfluency Detection / YOLO-Stutter: エンドツーエンドの領域別音声非流暢性検出

## 概要（3行で）
- 目的: 音声の非流暢性（repetition, block, missing, replacement, prolongation など）を時間領域で正確に検出・局在化するエンドツーエンド手法を確立。
- アプローチ: スピーチ-テキストのソフトアラインメントを入力に、空間特徴集約器＋時間依存抽出器により領域単位のバウンダリとクラスを同時予測（YOLO発想）。
- 結果: 合成（VCTK-TTS, VCTK-Stutter）, 公開コーパス, 臨床（失語症）データでSOTA級の精度を達成しつつ学習可能パラメータを最小化。

## 主な貢献
- YOLO-Stutter: 時間-周波数上の領域検出として非流暢性を扱うエンドツーエンド設計（テンプレート不要）。
- データセット: VCTK-Stutter（語・音素レベル拡張）, VCTK-TTS（自然性重視の合成）を新規作成し、広範な非流暢性をカバー。
- 臨床連携: 38名の失語症コホートでの実データ評価により、実運用への可能性を示唆。

## 手法 / 設計
- 入力: 参照テキストと音声からのソフトアラインメント（例: VITS由来）を特徴化。
- モデル: 空間特徴集約器（spectrogram-like）＋時間依存抽出器により、領域境界と非流暢性タイプを同時予測。
- 出力: 単語/音素レベルの領域ボックス＋クラス（region-wise prediction）。

## 実験・評価（要約）
- セットアップ: 合成（VCTK-TTS, VCTK-Stutter）、既存コーパス、公的データ、臨床データを横断。
- 指標: 時間領域の検出精度（例: F1/Precision/Recall, IoU 相当の一致指標）、計算効率、パラメータ数。
- 結果: 合成・実データとも高精度で、特に低パラメータ・実時間性に強み。

## 主要結果
- 同一条件の従来法（UDM/H-UDM系など）に対し、領域検出精度と推論効率で優位。
- 語・音素の両粒度での非流暢性タイプ検出を実現。

## 考察・限界
- 強み: 高速性・軽量性・一体型学習。アノテーション依存を軽減。
- 限界: 言語学的根拠の弱さや説明可能性の制約（臨床応用での可視化・根拠提示は今後課題）。
- 将来課題: アラインメント頑健化、臨床的説明可能性の付与、実環境ノイズ下の評価拡充。

## 再現性メモ
- コード/データ: https://github.com/rorizzz/YOLO-Stutter
- データ拡張: VCTK-Stutter, VCTK-TTS の生成ルール（テキスト・音響）を提示。

## 応用・拡張アイデア
- 臨床: 検出領域の可視化（時間-周波数上のボックス）で説明性を補助。
- 実時間アプリ: スクリーニングや言語学習向けの低遅延検出。
- ハイブリッド: 整合ベース（UDM 等）と組み合わせ、速度と説明性の両立を模索。

## キークォート
> "We propose YOLO-Stutter: a first end-to-end method that detects dysfluencies in a time-accurate manner."
> "We also introduce two dysfluency corpus, VCTK-Stutter and VCTK-TTS, ... naturalistic dysfluent speech."

## 用語メモ（words/ を使う）
- [[words/phoneme-alignment]]: 音素整合に基づく中間表現（関連）。
- [[words/vctk-stutter]]: 語・音素レベルの合成非流暢性コーパス。
- [[words/vctk-tts]]: TTS生成による自然性重視の合成コーパス。

## 関連研究
- UDM/H-UDM（2Dアラインメント型）との比較、検出パラダイム（YOLO系）の音声応用。

## BibTeX
```bibtex
@misc{zhou2024yolostutter,
  title         = {YOLO-Stutter: End-to-end Region-Wise Speech Dysfluency Detection},
  author        = {Xuanru Zhou and Anshul Kashyap and Steve Li and Ayati Sharma and Brittany Morin and David Baquirin and Jet Vonk and Zoe Ezzes and Zachary Miller and Maria Luisa Gorno-Tempini and Jiachen Lian and Gopala Krishna Anumanchipalli},
  year          = {2024},
  eprint        = {2408.15297},
  archivePrefix = {arXiv},
  primaryClass  = {eess.AS},
  url           = {https://arxiv.org/abs/2408.15297}
}
```

## リンク
- arXiv: https://arxiv.org/abs/2408.15297
- PDF: https://arxiv.org/pdf/2408.15297v3.pdf
- ローカルPDF: @pdf/2408.15297v3.pdf
